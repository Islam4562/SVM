# Support Vector Machines (SVM)

## Определение

SVM — это мощный алгоритм машинного обучения, который используется для задач классификации и регрессии. Его основная идея — найти **оптимальную гиперплоскость**, которая максимально разделяет классы в пространстве признаков.

## Оптимизационная задача SVM

Задача оптимизации в SVM формулируется как:

![Equation](https://latex.codecogs.com/png.latex?%5Cmin_%7Bw%2C%20b%7D%20%5Cfrac%7B1%7D%7B2%7D%20%5Cleft%5C%7Cw%5Cright%5C%7C%5E2)

при условиях:

![Equation](https://latex.codecogs.com/png.latex?y_i%28w%20%5Ccdot%20x_i%20%2B%20b%29%20%5Cgeq%201%2C%20%5Cforall%20i)

где:
- \( w \) — вектор весов,
- \( b \) — смещение,
- \( y_i \) — метки классов (\(+1\) или \(-1\)),
- \( x_i \) — вектор признаков.

## Критерий отступа (Margin)

Отступ определяется как:

![Equation](https://latex.codecogs.com/png.latex?%5Ctext%7BMargin%7D%20%3D%20%5Cfrac%7B1%7D%7B%5Cleft%5C%7Cw%5Cright%5C%7C%7D)

Чем больше отступ, тем лучше модель обобщает данные.

## Метод опорных векторов

Опорные векторы — это те образцы, которые находятся на границе **гиперплоскости разделения**. Они определяют положение разделяющей гиперплоскости.

## Функция потерь SVM

SVM использует **hinge loss function**:

![Equation](https://latex.codecogs.com/png.latex?L%28w%2C%20b%29%20%3D%20%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%20%5Cmax%280%2C%201%20-%20y_i%20%28w%20%5Ccdot%20x_i%20%2B%20b%29%29)

---

## **Вывод**
SVM является мощным алгоритмом для задач классификации и регрессии. Он работает эффективно даже в **высокоразмерных пространствах** и широко используется в задачах **распознавания образов, биоинформатики и финансового анализа**.
